<!DOCTYPE html>
<html lang="en">
<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Juliet&#39;s blog">
    <meta name="keyword" content>
    <link rel="shortcut icon" href="/junlian.github.io/img/favicon.ico">

    <title>
        
        梯度消失和梯度爆炸 - 学 | 慢慢来
        
    </title>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/junlian.github.io/css/aircloud.css">
    <link rel="stylesheet" href="/junlian.github.io/css/gitment.css">
    <!--<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">-->
    <link href="//at.alicdn.com/t/font_620856_pl6z7sid89qkt9.css" rel="stylesheet" type="text/css">
    <!-- ga & ba script hoook -->
    <script></script>
</head>

<body>

<div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i> 所谓诚其意者，毋自欺也，如恶恶臭，如好好色，此之谓自谦，故君子必慎其独也。 ——摘《大学》 </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        
<div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar ">
            <img src="/junlian.github.io/img/avatar.jpg" />
        </div>
        <div class="name">
            <i>慎思之，笃行之</i>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li >
                <a href="/junlian.github.io/">
                    <i class="iconfont icon-shouye1"></i>
                    <span>主页</span>
                </a>
            </li>
            <li >
                <a href="/junlian.github.io/tags">
                    <i class="iconfont icon-biaoqian1"></i>
                    <span>标签</span>
                </a>
            </li>
            <li >
                <a href="/junlian.github.io/archives">
                    <i class="iconfont icon-guidang2"></i>
                    <span>存档</span>
                </a>
            </li>
            <li >
                <a href="/junlian.github.io/about/">
                    <i class="iconfont icon-guanyu2"></i>
                    <span>关于</span>
                </a>
            </li>
            
            <li>
                <a id="search">
                    <i class="iconfont icon-sousuo1"></i>
                    <span>搜索</span>
                </a>
            </li>
            
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-梯度下降"><span class="toc-text">1. 梯度下降</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-梯度弥散"><span class="toc-text">2. 梯度弥散</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-梯度弥散原因"><span class="toc-text">2.1 梯度弥散原因</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-解决办法"><span class="toc-text">2.2 解决办法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-1-激活函数用ReLU"><span class="toc-text">2.2.1 激活函数用ReLU</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-2-BatchNormalization"><span class="toc-text">2.2.2 BatchNormalization</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-3-预训练-finetune"><span class="toc-text">2.2.3 预训练 + finetune</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-4-梯度剪切防止梯度爆炸"><span class="toc-text">2.2.4 梯度剪切防止梯度爆炸</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-5-正则化防止梯度爆炸"><span class="toc-text">2.2.5 正则化防止梯度爆炸</span></a></li></ol></li></ol></li></ol>
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input"/>
            <span id="begin-search">搜索</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>

        <div class="index-about-mobile">
            <i> 所谓诚其意者，毋自欺也，如恶恶臭，如好好色，此之谓自谦，故君子必慎其独也。 ——摘《大学》 </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        


<div class="post-container">
    <div class="post-title">
        梯度消失和梯度爆炸
    </div>

    <div class="post-meta">
        <span class="attr">发布于：<span>2019-09-01 13:24:34</span></span>
        
        <span class="attr">标签：/
        
        <a class="tag" href="/junlian.github.io/tags/#深度学习" title="深度学习">深度学习</a>
        <span>/</span>
        
        
        </span>
        <span class="attr">访问：<span id="busuanzi_value_page_pv"></span>
</span>
</span>
    </div>
    <div class="post-content no-indent">
        <h2 id="1-梯度下降"><a href="#1-梯度下降" class="headerlink" title="1. 梯度下降"></a>1. 梯度下降</h2><p>优化神经网络的方法是基于反向传播的，根据损失函数计算的误差通过梯度反向传播，来指导更新优化网络的权重。之所以这样做是因为深度网络由许多非线性层堆叠而成，可以把每一层看作一个非线性函数，这样深度网络就可以用一个复合的非线性多元函数表达：</p>
<script type="math/tex; mode=display">F(x) = f_n(...f_3((f_2(f_1(x) * \theta_1 + b_1) * \theta_2 + b_2)...))</script><p>假设对某一输入 $x$，输出的最优解是 $g(x)$，那么训练的目的是找到一组权值，使整个多元函数能很好地完成输入输出的映射，即$Loss = L(g(x), F(x))$ 取得极小值点。</p>
<h2 id="2-梯度弥散"><a href="#2-梯度弥散" class="headerlink" title="2. 梯度弥散"></a>2. 梯度弥散</h2><p>梯度弥散是指，随着网络层数的加深，在反向传播过程中，越靠近输入层，隐藏层的权值更新就越缓慢甚至停滞（梯度消失），或者越来越快（梯度爆炸），相当于网络训练时只训练了后面几层的网络。梯度很小，意味着参数的变化很缓慢，学习过程停滞。</p>
<h3 id="2-1-梯度弥散原因"><a href="#2-1-梯度弥散原因" class="headerlink" title="2.1 梯度弥散原因"></a>2.1 梯度弥散原因</h3><p>反向传播方式是用链式求导，在计算每一层梯度的时候，会涉及连乘操作，如果网络非常深，会出现梯度消失和梯度爆炸的问题。</p>
<p>例如有一个 L层的神经网络，代价函数$C$是网络最后一层输出$h_L$的函数，中间第 l 层的某一节点激活情况如下：</p>
<script type="math/tex; mode=display">z_l = w_l h_{l-1}+ b_l</script><script type="math/tex; mode=display">h_l = \sigma(z_l)</script><p>激活函数用sigmoid：</p>
<script type="math/tex; mode=display">\sigma(z) = S(z) = \frac{1}{1+e^{-z}} = \frac{e^x}{e^x + 1}</script><p>激活函数的导数为：</p>
<script type="math/tex; mode=display">\sigma(z) =S'(z) = \frac{e^{-z}}{(1+e^{-z})^2} = S(z) (1-S(z))</script><p>Sigmoid的导数值的范围在0-0.25，最大值0.25在 z=0 处取到。</p>
<p>假设要更新参数 $b_1$，就需要求出损失函数对参数 $b_1$ 的梯度 ：</p>
<script type="math/tex; mode=display">
\begin{array}{ll}
\frac{\partial C}{\partial b_1} &=& \frac{\partial h_1}{\partial z_1} \times \frac{\partial z_2}{\partial h_1} \times \frac{\partial h_2}{\partial z_2} \times \frac{\partial z_3}{\partial h_2} \times ... \times \frac{\partial C}{\partial h_L} \\
&=& \sigma'(z_1) w_2 \sigma'(z_2) w_3 ...\frac{\partial C}{\partial h_L} 
\end{array}</script><p>其中，$0 \le \sigma’(z_l) \le 0.25$， 当初始化网络权重 |w| 小于1时，随着网络层数的增加，小于1的值不断连乘会出现 <strong>“梯度消失”</strong>；当初始化权重 |w| 较大，$|\sigma’(z)w| &gt; 1$ 时，会出现 <strong>“梯度爆炸”</strong>。</p>
<h3 id="2-2-解决办法"><a href="#2-2-解决办法" class="headerlink" title="2.2 解决办法"></a>2.2 解决办法</h3><h4 id="2-2-1-激活函数用ReLU"><a href="#2-2-1-激活函数用ReLU" class="headerlink" title="2.2.1 激活函数用ReLU"></a>2.2.1 激活函数用ReLU</h4><p>ReLU：当x大于0时，导数为1<br>(<a href="https://kjuliet.github.io/junlian.github.io/2019/08/17/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/" target="_blank" rel="noopener">激活函数详解</a>)</p>
<h4 id="2-2-2-BatchNormalization"><a href="#2-2-2-BatchNormalization" class="headerlink" title="2.2.2 BatchNormalization"></a>2.2.2 BatchNormalization</h4><p>反向传播中权重$w_2w_3…$ 的大小会影响梯度消失和爆炸，BatchNormalization是对每一层的输出做规范化操作，消除$w_2w_3…$ 带来的放大缩小的影响。降低了数据之间的绝对差异，更多地考虑相对差异，将输出从饱和区拉到了非饱和区。</p>
<p><a href="https://kjuliet.github.io/junlian.github.io/2019/08/26/Batch-Normalization-ICML-2015/" target="_blank" rel="noopener">BatchNormalization 详解</a></p>
<h4 id="2-2-3-预训练-finetune"><a href="#2-2-3-预训练-finetune" class="headerlink" title="2.2.3 预训练 + finetune"></a>2.2.3 预训练 + finetune</h4><p>最初的思想是逐层预训练，每次训练一层隐藏层，每一层训练完将本层的输出作为下一层的输入，全部训练完后再对整个网络进行 finetune，先找局部最优，再整合起来找全局最优。</p>
<p>现在基本是拿到一个预训练的模型，直接进行finetune。</p>
<h4 id="2-2-4-梯度剪切防止梯度爆炸"><a href="#2-2-4-梯度剪切防止梯度爆炸" class="headerlink" title="2.2.4 梯度剪切防止梯度爆炸"></a>2.2.4 梯度剪切防止梯度爆炸</h4><p>设一个阈值，但更新时梯度超过这个阈值，就强制限制在这个范围内，防止梯度爆炸。</p>
<h4 id="2-2-5-正则化防止梯度爆炸"><a href="#2-2-5-正则化防止梯度爆炸" class="headerlink" title="2.2.5 正则化防止梯度爆炸"></a>2.2.5 正则化防止梯度爆炸</h4><p>正则化是通过对网络权重做正则来防止过拟合，如果发生梯度爆炸，权重的范数会变得非常大，所以通过正则化在一定程度上可以限制梯度爆炸。</p>

        
        <br />
        <div id="comment-container">
        </div>
        <div id="disqus_thread"></div>

        <div id="lv-container">
        </div>

    </div>
</div>

    </div>
</div>


<footer class="footer">
    <ul class="list-inline text-center">
        
        

        

        

        

        

    </ul>
    
    <p>
        <span id="busuanzi_container_site_pv">
            <span id="busuanzi_value_site_pv"></span>PV
        </span>
        <span id="busuanzi_container_site_uv">
            <span id="busuanzi_value_site_uv"></span>UV
        </span>
        Created By <a href="https://hexo.io/">Hexo</a>  Theme <a href="https://github.com/aircloud/hexo-theme-aircloud">AirCloud</a></p>
</footer>




<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });

</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<!-- <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->

</body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = "search.json"
    window.hexo_root = "/junlian.github.io/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>
<script src="/junlian.github.io/js/index.js"></script>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




</html>
